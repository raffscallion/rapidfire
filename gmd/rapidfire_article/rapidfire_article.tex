%% Copernicus Publications Manuscript Preparation Template for LaTeX Submissions
%% ---------------------------------
%% This template should be used for copernicus.cls
%% The class file and some style files are bundled in the Copernicus Latex Package, which can be downloaded from the different journal webpages.
%% For further assistance please contact Copernicus Publications at: production@copernicus.org
%% https://publications.copernicus.org/for_authors/manuscript_preparation.html

%% copernicus_rticles_template (flag for rticles template detection - do not remove!)

%% Please use the following documentclass and journal abbreviations for discussion papers and final revised papers.

%% 2-column papers and discussion papers
\documentclass[gmd, manuscript]{copernicus}



%% Journal abbreviations (please use the same for preprints and final revised papers)

% Advances in Geosciences (adgeo)
% Advances in Radio Science (ars)
% Advances in Science and Research (asr)
% Advances in Statistical Climatology, Meteorology and Oceanography (ascmo)
% Annales Geophysicae (angeo)
% Archives Animal Breeding (aab)
% Atmospheric Chemistry and Physics (acp)
% Atmospheric Measurement Techniques (amt)
% Biogeosciences (bg)
% Climate of the Past (cp)
% DEUQUA Special Publications (deuquasp)
% Drinking Water Engineering and Science (dwes)
% Earth Surface Dynamics (esurf)
% Earth System Dynamics (esd)
% Earth System Science Data (essd)
% E&G Quaternary Science Journal (egqsj)
% EGUsphere (egusphere) | This is only for EGUsphere preprints submitted without relation to an EGU journal.
% European Journal of Mineralogy (ejm)
% Fossil Record (fr)
% Geochronology (gchron)
% Geographica Helvetica (gh)
% Geoscience Communication (gc)
% Geoscientific Instrumentation, Methods and Data Systems (gi)
% Geoscientific Model Development (gmd)
% History of Geo- and Space Sciences (hgss)
% Hydrology and Earth System Sciences (hess)
% Journal of Bone and Joint Infection (jbji)
% Journal of Micropalaeontology (jm)
% Journal of Sensors and Sensor Systems (jsss)
% Magnetic Resonance (mr)
% Mechanical Sciences (ms)
% Natural Hazards and Earth System Sciences (nhess)
% Nonlinear Processes in Geophysics (npg)
% Ocean Science (os)
% Polarforschung - Journal of the German Society for Polar Research (polf)
% Primate Biology (pb)
% Proceedings of the International Association of Hydrological Sciences (piahs)
% Safety of Nuclear Waste Disposal (sand)
% Scientific Drilling (sd)
% SOIL (soil)
% Solid Earth (se)
% The Cryosphere (tc)
% Weather and Climate Dynamics (wcd)
% Web Ecology (we)
% Wind Energy Science (wes)

% Pandoc citation processing

% The "Technical instructions for LaTex" by Copernicus require _not_ to insert any additional packages.
% 
% tightlist command for lists without linebreak
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}


%
\begin{document}


\title{A model for rapid wildfire smoke exposure estimates using
routinely-available data}


\Author[1]{Sean}{Raffuse}
\Author[2]{Susan}{O'Neill}
\Author[3]{Rebecca}{Schmidt}


\affil[1]{Air Quality Research Center, University of California Davis,
Davis, CA, United States}
\affil[2]{Pacific Northwest Research Station, USDA Forest Service,
Seattle, WA, United States}
\affil[3]{Department of Public Health Sciences, MIND Institute,
University of California Davis School of Medicine, Davis, CA, United
States}

\runningtitle{rapidfire for Smoke Exposure Modeling}

\runningauthor{Raffuse et al.}


\correspondence{Sean\ Raffuse\ (sraffuse@ucdavis.edu)}



\received{}
\pubdiscuss{} %% only important for two-stage journals
\revised{}
\accepted{}
\published{}

%% These dates will be inserted by Copernicus Publications during the typesetting process.


\firstpage{1}

\maketitle


\begin{abstract}
Urban smoke exposure events from large wildfires have become
increasingly common in California and through the western United States.
The ability to study the impacts of high smoke aerosol exposures from
these events on the public is limited by the availability of
high-quailty, spatially-resolved estimates of aerosol concentrations.
Methods for the assigning aerosol exposure often employ multiple data
sets that are time consuming and expensive to create and difficult to
reproduce. As these events have gone from occasional to nearly annual in
frequency, the need for rapid smoke exposure assessments has increased.
The rapidfire R package provides a suite a tools for developing exposure
assigments using data sets that are routinely generated and publicly
available within a month of the event. Specifically, rapidfire harvests
official air quality monitoring, satellite observations, meteorological
modeling, operational predictive smoke modeling, and low-cost sensor
networks. A machine learning approach (random forests regression) is
used to fuse the different data sets. Using rapidfire, we produced
estimates of ground-level 24-hour average PM\textsubscript{2.5} over for
several large wildfire smoke events in California from 2017-2021. These
estimates show excellent agreement with independant measures of
PM\textsubscript{2.5} from filter-based networks.
\end{abstract}


\copyrightstatement{The author's copyright for this publication is
transferred to institution/company.}


\introduction[Introduction]

Changes in climate in the western United States, and elsewhere, are
driving larger, more intense fires with greater smoke impacts on larger
populations \citep{Burke2021}, and these trends are projected to
continue \citep{Hurteau2014}. The wildfire seasons of 2020 and 2021
produced some of the highest concentrations of PM\textsubscript{2.5}
ever observed in monitoring stations around California, some for several
days or weeks. Despite reductions in ambient PM\textsubscript{2.5}
driven by air pollution regulations, areas of the western United States
are seeing increasing concentrations \citep{McClure2018}.\\
The health impacts of exposure to wildfire smoke are wide-ranging.

\{Rebecca's paragraphs here\}

Despite these findings, many gaps remain in our understanding of the
linkages between wildfire smoke and human health \citep{Black2017}. A
critical challenge is in characterizing personal or population exposures
during high-intensity events. There are many methods for estimating
exposure to ambient pollution, including spatial interpolation of
measured values, chemical transport modeling, remote sensing, land-use
regression modeling, data fusion and machine learning, and combinations
of all of these approaches (e.g., \citet{Reid2015}, \citet{Zhang2020},
\citet{Al-Hamdan2014}, \citet{Cleland2020}, \citet{Hoek2008}). The
rapidly changing conditions during wildfire smoke events can confound
otherwise high-performing approaches \citep{ONeill2021}. There are
several barriers to the adoption of existing methods for exposure
assignment. These can include data availability for the study location,
data latency, and high-performance computing requirements. The
combination of increasing frequency of smoke events and the
proliferation of smoke exposure human health studies drives a need for
exposure modeling that is rapid and inexpensive.\\
There has been a rapid proliferation of low-cost sensors for air quality
within the past decade. While these sensors do not measure
PM\textsubscript{2.5} with the same fidelity as the regulatory
monitoring conducted by federal and local air quality agencies, they
represent a new resource for PM\textsubscript{2.5} assessment with
relatively dense spatial coverage. Many low-cost PM sensors operate with
similar principles, using a laser to count particles that scatter light
in the optical range, with a bias toward accumulation mode particles (PM
with aerodynamic diameter \textless{} 0.3, \citet{Ouimette2022}). Recent
studies have shown the value of incorporating low-cost sensor networks
into PM\textsubscript{2.5} exposure modeling \citep{Bi2020}.\\
Past work has shown that a data fusion approach that combines
ground-based air quality monitors, transport modeling that incorporates
wildfire emissions, satellite observations, and meteorological variables
can be effective in predicting PM\textsubscript{2.5} exposure during
large wildfire events \citep[ and \citet{ONeill2021}]{Zou2019}.\\
We developed a method a suite of tools for rapidly predicting
PM\textsubscript{2.5} exposure, particularly during wildfire smoke
events, using readily available data with low latency (less than one
month). The tools are contained within a package written in the R
programming language called rapidfire (relatively accurate particulate
information derived from information retrieved easily). rapidfire adapts
and builds upon the methods of \citet{Zou2019} and \citet{ONeill2021},
replacing retrospective chemical transport modeling and other data sets
developed for research with smoke forecast modeling and
``off-the-shelf'' data sets that are routinely available and easily
acquired. A major addition is the incorporation of low-cost sensor data.
This paper describes the data sets and algorithms used in the rapidfire
package and presents an example case study during four recent extreme
wildfire seasons in California.

\section{Methods}

\subsection{Input Data Sets}

\subsubsection{Official and Temporary Monitoring}

Hourly PM\textsubscript{2.5} observations are available from monitoring
stations across the United States via the AirNow network {[}ref{]}.
Within California, about {[}number{]} of monitors were operating during
the study period. These permanent monitors are a mixture of federal
reference method or federal equivalent method instruments, meaning that
they are approved by the US EPA to calculate and report air quality to
the public.\\
During wildfires, temporary monitors are also deployed by several
government agencies, such as the California Air Resources Board (CARB),
and the USDA Forest Service (USFS). These are mostly {[}what{]}. Though
they are not as accurate as the AirNow monitors {[}ref{]}, they are
deployed in regions where smoke impacts are significant and permanent
monitoring is sparse or absent. The locations of permanent and temporary
monitors as of September 1, 2021 is shown in Figure \ref{fig:monitors}.
The permanent monitors are concentrated in the coastal and valley
regions, while temporary monitors are focused in areas of complex
terrain where most wildfires are located.

\begin{figure}[h]
\includegraphics[width=8.3cm]{./Figures/MonitorsGMD} \caption{Map of permanent and temporary California monitor locations as of September 1, 2021.}\label{fig:monitors}
\end{figure}

Hourly PM\textsubscript{2.5} concentrations from both the permanent and
temporary monitors were acquired using the
\texttt{rapidfire::get\_airnow\_daterange} and
\texttt{rapidfire::get\_airsis\_daterange} functions. These wrap the
\texttt{monitor\_subset} function from the \texttt{PWFSLSmoke} R package
{[}Mazama Science{]}. \texttt{rapidfire::recast\_monitors} was then used
to calculate daily 24-hr averages from the hourly data. At least 16
hours are required to produce an average.\\
The daily average data from both the permanent and temporary monitors
were combined into a single data set. The spatial extent of the monitors
used in this analysis are shown in Figure {[}xx{]}. Portions of this
monitor data set were withheld for development and validation of the
model. PM\textsubscript{2.5} observations were log-transformed and
interpolated to estimate concentrations at locations away from the
monitors using ordinary kriging. 30\% of the monitoring data were
withheld as test data to develop model variograms using
\texttt{rapidfire::create\_airnow\_variograms}.

\subsubsection{Smoke Modeling}

Air quality models provide ground-level estimates of
PM\textsubscript{2.5} on an output grid. We processed daily average
values acquired from the BlueSky Daily Run Viewer (Websky), developed by
the USFS AirFire Team. Depending on the event year, different model runs
were available. Modeling from Websky was chosen because it is available
operationally, is high spatial resolution, and is focused specifically
on modeling smoke aerosols from wildland fires; however, other air
quality modeling could be substituted. {[}Susan, can you help me here to
describe which models were used and their references?{]} On some days,
the model did not run successfully. For those days, data were backfilled
by using the second our third day of a previous day's 72-hr model run.

\subsubsection{Satellite Aerosol Optical Depth}

Satellite aerosol optical depth (AOD) is a measure of the total columnar
aerosol light extinction from the satellite sensor to the ground. AOD is
indirectly related to PM\textsubscript{2.5}, with the relationship
depending on aerosol type, humidity, and aerosol vertical profile
\citep{Li2015}. We used AOD from the Multi-Angle Implementation of
Atmospheric Correction (MAIAC) project \citep{Lyapustin2011}. MAIAC is
an algorithm that uses time series analysis and additional processing to
improve aerosol retrievals, atmospheric correction, and, importantly,
cloud detection from the MODerate-resolution Imaging Spectroradiometers
(MODIS) onboard NASA's Terra and Aqua satellites. Past work has shown
that thick smoke is often mistaken for clouds in the standard MODIS
algorithms \citep{vanDonkelaar2011}, which hampers their use in wildfire
conditions.\\
The \texttt{rapidfire::maiac\_download} function can be used to acquire
the 1-km daily atmosphere product (MCD19A2) which contains AOD. Clouds
prevent the retrieval of AOD, and there are sometimes clouds present
even in the hot, dry conditions during California wildfires. The data
fusion algorithm requires a complete data set, so a placeholder value
must be used to gap-fill in locations under clouds. Previous work has
used model-simuluated AOD, along with meteorological variables in a data
fusion approach to gap-fill satellite-observed AOD \citep{Zou2019}. For
this work, where clouds cover less of the domain, we took a simpler
approach. Missing AOD values were filled using a three-stage focal
average, available in \texttt{rapidfire::maiac\_fill\_gaps\_complete},
and illustrated in Figure \ref{fig:gapfill}. In the first stage, a focal
mean of a 5-by-5 pixel square (5 km) is used. In the second state, the
window is increased to 9-by-9 and to 25-by-25 in the final stage. Any
values that are still missing after the final stage are filled with the
median value for the entire scene.

\begin{figure}[h]
\includegraphics[width=8.3cm]{./Figures/GapFillingGMD} \caption{Illustration of MAIAC AOD gap filling}\label{fig:gapfill}
\end{figure}

\subsubsection{Low-cost Sensors}

There has been a proliferation of low-cost sensors that estimate
PM\textsubscript{2.5} deployed by the public across the world in the
last decade. We used data from the PurpleAir network, which has grown to
over 6500 outdoor sensors in California as of 2021. Figure
\ref{fig:sensors} shows the locations of PurpleAir sensors reporting
data on September 1, 2021. Coverage in populated areas is extensive.\\

\begin{figure}[h]
\includegraphics[width=8.3cm]{./Figures/SensorsGMD} \caption{Map of California PurpleAir outdoor sensor locations as of September 1, 2021.}\label{fig:sensors}
\end{figure}

While PurpleAir estimates of PM\textsubscript{2.5} concentration have
been shown to be biased, and are dependent on humidity and aerosol type
\citep{Barkjohn2021}, they still correlate with PM\textsubscript{2.5}
observed at FEM monitors and provide invaluable spatial and temporal
information that is not available with the relatively sparse network of
monitors. Because these sensors are not quality controlled or validated,
and their sighting may be suspect, care must be taken when using them in
modeling.\\
rapidfire takes advantage of the AirSensor R package {[}Mazama
Science{]} for discovering and acquiring PurpleAir sensor data from
sensors designated as ``outdoor.''
\texttt{rapidfire::create\_purpleair\_archive} was used to download and
preprocess PurpleAir data from two-channel, 1-minute estimates to single
24-hr average values. The two channels were compared and data were only
kept if both values were low (\(<2\,\unit{\mu g\,m^{-3}}\)) or were
within a scaled relative difference (\(SRD\)) between channels \(A\) and
\(B\) of 0.5. A daily mean was calculated for both channels and those
were then averaged to produce a final daily estimate for the sensor.

\begin{equation}
SRD=\frac{A-B}{\sqrt{2}}/\frac{A+B}{2}.  
\end{equation}

In addition to the channel comparison, we also employed a spatial test
to remove sensors that were significantly different from their
neighbors. rapidfire::purpleair\_clean\_spatial\_outliers removes any
sensors that are more that two standard deviations away from the median
of all sites within \(10\unit {km}\). PurpleAir estimates used in data
fusion were log-transformed and then interpolated using ordinary
kriging.

\subsubsection{Meteorology}

Meteorological conditions can help explain the relationships between our
inputs and observed PM\textsubscript{2.5}. For example, the PurpleAir
sensor is sensitive to relative humidity. AOD is sensitive to humidty
and planetary boundary layer height. Following Zou et al.~(2019), we
included several meteorological variables in our model, including
temperature, winds, humidity, boundary layer height, and rainfall. These
variables were acquired from the North American Regional Reanalysis
(NARR) data set \citep{Mesinger2006}.

\subsection{Data Fusion}

We developed event specific models using random forests regression (RF).
RF is a technique that uses a large number of randomly generated
regression trees \citep{Breiman2001}. Each tree is constructed using a
random subset of the training data and each node uses a random subset of
the potential predictive variables. New values are estimated as the mean
prediction of the individual trees. For each RF run, 500 trees were
grown. A single tuning parameter, the number of variables selected at
each node, was varied between 2 and 5. The model was trained using
10-fold cross-validation. Internally, \texttt{rapidfire::develop\_model}
uses the randomForest R package.\\
For the final model, 10 predictor variables were used (Table
\ref{table:1}). PM\textsubscript{2.5} from the monitors was used as both
a predictor and a target variable. A random subset of 30\% of the
monitoring data was withheld for model validation.

\begin{table}[h]
\caption{Predictor variables used in the rapidfire RF model.}
\begin{tabular}{ll}
Variable       & Description                                                                    \\ \hline
PM25\_log\_ANK & Log-transformed, interpolated $PM_{2.5}$ from permanent and temporary monitors \\
PM25\_log\_PAK & Log-transformed, interpolated $PM_{2.5}$ estimates from PurpleAir sensors      \\
PM25\_bluesky  & Daily average ground-level $PM_{2.5}$ predictions from BlueSky smoke model     \\
MAIAC\_AOD     & Gap-filled  daily AOD from MAIAC                                               \\
air.2m         & Daily average ambient temperature at $2\unit{m}$ above ground level from NARR  \\
uwnd.10m       & Daily average u component of wind at $10\unit{m}$ above ground level from NARR \\
vwnd.10m       & Daily average v component of wind at $10\unit{m}$ above ground level from NARR \\
rhum.2m        & Daily average relative humidity at $2\unit{m}$ above ground level from NARR    \\
apcp           & Daily total precipitation amount from NARR                                     \\
hpbl           & Daily average height of the planetary boundary layer from NARR                
\end{tabular}
\label{table:1}
\end{table}

\subsection{Model Validation}

We developed models for five large wildfire smoke events from 2017-2021
in Northern California (Table \ref{table:2}) and validated the modeling
against two data sets of PM\textsubscript{2.5} observations, 1) the
permanent and temporary hourly monitors described above, and 2) 24-hr
filter-based measurements from the IMPROVE and CSN networks.

\begin{table}[h]
\caption{Modeled time periods and major Northern California wildfires}
\begin{tabular}{lll}
Year & Time Period              & Major Fires                                        \\ \hline
2017 & October                  & Atlas, Nuns, Pocket, Redwood Valley, Tubbs         \\
2018 & July 15 - September 15; November   & Carr, Camp                               \\
2019 & October 15 - November 15 & Thomas                                             \\
2020 & August - October         & August, Creek, LNU Lightning, North, SCU Lightning \\
2021 & August - October         & Antelope, Caldor, Dixie, Monument, River          
\end{tabular}
\label{table:2}
\end{table}

\subsubsection{Hourly Monitors}

Model predicted PM\textsubscript{2.5} values were compared against
withheld measurements from the permanent and temporary monitoring
networks using rapidfire and three other modeling techniques: 1)
ordinary kriging (OK) interpolation of AirNow monitors, 2) OK
interpolation of PurpleAir sensors, and 3) multiple linear regression
(MLR) using the same inputs as those used for the rapidfire modeling.
Comparative model performance metrics are presented in Table
\ref{table:3}. For these wildfire events, rapidfire provides good
correlation with low error and bias, offering advantages over classical
MLR or interpolation of the ground monitors alone. Graphical results of
the validation (Figure \ref{fig:methods}) show the tighter distribution
around the 1:1 line for the rapidfire modeling, especially for higher
concentrations.

\begin{table}[h]
\caption{Performance metrics for four modeling methods}
\begin{tabular}{lrrrrrr}
Model     & R\textsuperscript{2}    & RMSE    & Median Bias    & Normalized Bias   & Median Error   & Normalized Error    \\ \hline
rapidfire & 0.74  & 21.5    & 0.083   & 0.76              & 2.13    & 18.6 \\
MLR       & 0.68  & 23.8    & 0.056   & 0.49              & 2.59    & 22.6  \\
AirNow OK & 0.63  & 25.7    & 0.133   & 1.22              & 2.63    & 23.0  \\
PurpleAir OK & 0.38 & 33.3  & -0.095  & -1.04             & 3.75    & 32.8
\end{tabular}
\label{table:3}
\end{table}

\begin{figure}
\includegraphics[width=12cm]{./Figures/MethodComparisonGMD} \caption{Model comparison against measured PM~2.5~ from the IMPROVE and CSN filter networks.}\label{fig:methods}
\end{figure}

\subsubsection{IMPROVE, CSN, CA FRM}

rapidfire results were also compared with available 24-hr integrated
filter-based observations from the IMPROVE and CSN networks. They
represent a challenging test of the method as they are 100\% independent
of the model inputs, accurate estimates of PM\textsubscript{2.5}
concentration, and, for IMPROVE especially, located far from other
monitors in remote locations with complex terrain. Downsides of using
these data are that the networks are more sparse and the days with the
highest concentrations are often not available as the IMPROVE sampler
can clog in very heavy smoke situations. Paired results are plotted in
Figure \ref{fig:filters}, showing good agreement across the
concentration range with a few outliers at IMPROVE sites. Model
performance metrics for the filter-based comparison are shown in Table
\ref{table:4}. As expected, the CSN sites are better predicted, as they
are typically located in urban areas with nearby AirNow monitors and
PurpleAir sensors.

\begin{table}[h]
\caption{Performance metrics for rapidfire at IMPROVE sites, CSN sites, and IMPROVE and CSN sites combined}
\begin{tabular}{lrrrrrr}
Network     & R\textsuperscript{2}    & RMSE    & Median Bias    & Normalized Bias   & Median Error   & Normalized Error    \\ \hline
CSN     & 0.82  & 5.18    & 0.42   & 3.93  & 1.96 & 15.3  \\
IMPROVE & 0.76  & 8.47    & 2.48   & 46.5  & 3.19 & 49.6   \\
Both    & 0.77  & 7.52    & 1.84   & 22.4  & 2.70 & 29.9
\end{tabular}
\label{table:4}
\end{table}

\section{Results}

\begin{figure}
\includegraphics[width=8.3cm]{./Figures/Model_vs_Filters_FiveEpisodesGMD} \caption{Model comparison against measured PM~2.5 at IMPROVE and CSN monitors}\label{fig:filters}
\end{figure}

The results are plotted across California for two wildfire seasons:
August - October, 2020 (\ref{fig:res_2020}) and August - October, 2021
(\ref{fig:res_2021}). In each case, daily average PM\textsubscript{2.5}
reaches values greater than \(200\,\unit{\mu g\,m^{-3}}\), with very
strong spatial and temporal variability. The 2020 case shows three
widespread peaks, in August, September, and October. In the 2021 case,
concentrations were highest in northern locations in August, while
values were higher further south in September and early October. These
two cases highlight the complexity of these smoke events, which are
controlled by multiple wildfires burning in and around the state.

\begin{figure}
\includegraphics[width=0.4\linewidth]{./Figures/Sparkmap2020} \includegraphics[width=0.4\linewidth]{./Figures/SparkLegend2020} \caption{2020}\label{fig:res_2020}
\end{figure}

\begin{figure}
\includegraphics[width=0.4\linewidth]{./Figures/Sparkmap2021} \includegraphics[width=0.4\linewidth]{./Figures/SparkLegend2021} \caption{2021}\label{fig:res_2021}
\end{figure}

\section{Code?}

\section{Discussion}

\subsection{Model input importance}

Although the random forest model uses all of the provided predictor
variables, the most explanatory variables are selected more often at
each node. The relative importance of each variable can calculated by
adding noise to each predictor variable in turn and examining the impact
on model prediction errors \citep{Breiman2001}. A plot of relative
importance of each variable is shown in \ldots\ldots..

\subsection{Application for health studies}

The rapidfire modeling has been applied, and is being applied, in
several epidemiological studies, including B-SAFE, WHAT-NOW, others?
{[}need help from Rebecca here. What can we put that has already been
published?{]} These have found interesting things, such as A, B, and C.

\subsection{Advantages over existing methods}

The primary advantages of the rapidfire methods. - open code - use of
production data sets - rapid development - adaptability to other
regions, time periods, and input data sets - focus on inputs important
for wildfire smoke

\subsection{Limitations}

\begin{itemize}
\tightlist
\item
  Need for training data
\item
  black box nature of random forests
\item
  current only includes data sets in the US
\end{itemize}

\conclusions[Conclusions]

The conclusion goes here. You can modify the section name with
\texttt{\textbackslash{}conclusions{[}modified\ heading\ if\ necessary{]}}.



\codedataavailability{use this to add a statement when having data sets
and software code
available} %% use this section when having data sets and software code available

\sampleavailability{use this section when having geoscientific samples
available} %% use this section when having geoscientific samples available

\videosupplement{use this section when having video supplements
available} %% use this section when having geoscientific samples available

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% optional

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\appendix
\section{Figures and tables in appendices}

Regarding figures and tables in appendices, the following two options
are possible depending on your general handling of figures and tables in
the manuscript environment:

\subsection{Option 1}

If you sorted all figures and tables into the sections of the text,
please also sort the appendix figures and appendix tables into the
respective appendix sections. They will be correctly named
automatically.

\subsection{Option 2}

If you put all figures after the reference list, please insert appendix
tables and figures after the normal tables and figures.

To rename them correctly to A1, A2, etc., please add the following
commands in front of them: \texttt{\textbackslash{}appendixfigures}
needs to be added in front of appendix figures
\texttt{\textbackslash{}appendixtables} needs to be added in front of
appendix tables

Please add \texttt{\textbackslash{}clearpage} between each table and/or
figure. Further guidelines on figures and tables can be found below.
\noappendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\authorcontribution{Daniel wrote the package. Josiah thought about
poterry. Markus filled in for a second author.} %% optional section

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\competinginterests{The authors declare no competing
interests.} %% this section is mandatory even if you declare that no competing interests are present

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\disclaimer{We like Copernicus.} %% optional section

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{acknowledgements}
Thanks to the rticles contributors!
\end{acknowledgements}

%% REFERENCES
%% DN: pre-configured to BibTeX for rticles

%% The reference list is compiled as follows:
%%
%% \begin{thebibliography}{}
%%
%% \bibitem[AUTHOR(YEAR)]{LABEL1}
%% REFERENCE 1
%%
%% \bibitem[AUTHOR(YEAR)]{LABEL2}
%% REFERENCE 2
%%
%% \end{thebibliography}

%% Since the Copernicus LaTeX package includes the BibTeX style file copernicus.bst,
%% authors experienced with BibTeX only have to include the following two lines:
%%
\bibliographystyle{copernicus}
\bibliography{rapidfire.bib}
%%
%% URLs and DOIs can be entered in your BibTeX file as:
%%
%% URL = {http://www.xyz.org/~jones/idx_g.htm}
%% DOI = {10.5194/xyz}


%% LITERATURE CITATIONS
%%
%% command                        & example result
%% \citet{jones90}|               & Jones et al. (1990)
%% \citep{jones90}|               & (Jones et al., 1990)
%% \citep{jones90,jones93}|       & (Jones et al., 1990, 1993)
%% \citep[p.~32]{jones90}|        & (Jones et al., 1990, p.~32)
%% \citep[e.g.,][]{jones90}|      & (e.g., Jones et al., 1990)
%% \citep[e.g.,][p.~32]{jones90}| & (e.g., Jones et al., 1990, p.~32)
%% \citeauthor{jones90}|          & Jones et al.
%% \citeyear{jones90}|            & 1990


\end{document}
